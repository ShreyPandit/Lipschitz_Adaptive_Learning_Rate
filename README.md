# Lipschitz Adaptive Learning Rate
<br>
This is an implemetation of paper by:- <br>
Yedida, Rahul, and Snehanshu Saha. "A novel adaptive learning rate scheduler for deep neural networks." arXiv preprint arXiv:1902.07399 (2019).
<br>
Using keras and Tensorflow . Main function is lr_scheduler which uses the callback of LRScheduler. All the code can be found in this repository . <br>
The summary sheet is made which contains the result for all of the datasets.<br>
The datasets on which this LALR is implemented are:-<br>
<ul>
  <li>MNIST </li>
  <li>IRIS </li>
  <li>Boston Housing data </li>
  <li>CIFAR-10 </li>
  <li>CIFAR-100 </li>
</ul>

# Setup Requirements 
<br>
The code uses the following packages that must be installed <br>
<ul>
  <li>Keras</li>
  <li>Tensoflow</li>
  <li>SKLearn</li>
  <li>Numpy </li>
  <li>Matplotlib</li>
  <li>TQDM</li>
</ul>

# Citation
If you find the following work useful please cite the paper-<br>
@article{yedida2019novel,
  title={A novel adaptive learning rate scheduler for deep neural networks},
  author={Yedida, Rahul and Saha, Snehanshu},
  journal={arXiv preprint arXiv:1902.07399},
  year={2019}
}
